<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Cam ChickenBanana</title>
    <style>
 html, body {
  background: #000;
  text-align: center;
}

#container {
  position: relative;
  width: 240px;
  height: 320px;
  margin: 0 auto;
}

#video {
  width: 240px;
  height: 320px;
  object-fit: cover;
  transform: scaleX(-1);
}

#emoji {
  position: absolute;
  font-size: 32px;
  width: 32px;
  height: 32px;
  user-select: none;
  cursor: grab;
}
#mouth-box {
  position: absolute;
  border: 2px solid red;
  pointer-events: none;
  display: none;
}
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay muted playsinline></video>
    <div id="emoji">üçå</div>
    <div id="mouth-box"></div>
  </div>

  <!-- TensorFlow.js and Face API -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.7.4/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const emoji = document.getElementById('emoji');
    const mouthBox = document.getElementById('mouth-box');
    const container = document.getElementById('container');

    const EMOJIS = ['üçå', 'üçó'];
    let currentEmojiIndex = 0;

    // Speak a word
    function speak(word) {
	  const msg = new SpeechSynthesisUtterance(word);
	  const voices = window.speechSynthesis.getVoices();

	  // Pick a deeper male voice (this one is usually present on Chrome)
	  const voice = voices.find(v => v.name === 'Google UK English Male');

	  // Fallback if not found
	  msg.voice = voice || voices.find(v => v.name.includes('Male')) || voices[0];

	  msg.lang = 'en-GB';  // Match the voice language
	  msg.rate = 0.9;      // Slightly slower for depth
	  msg.pitch = 0.1;     // Lower pitch for deeper tone

	  window.speechSynthesis.speak(msg);
	}

    // Start camera
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 240, height: 320 }
        });
        video.srcObject = stream;
      } catch (err) {
        alert('Camera error: ' + err);
      }
    }

    // Load models
    async function loadModels() {
      const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68TinyNet.loadFromUri(MODEL_URL);
    }

    function mirrorX(x, videoWidth, containerWidth) {
      return containerWidth - (x * containerWidth / videoWidth);
    }

    function isMouthOpen(landmarks) {
      const mouth = landmarks.getMouth();
      const topLip = mouth[13];
      const bottomLip = mouth[19];
      const openDist = bottomLip.y - topLip.y;
      return openDist > 12; // Adjust threshold if needed
    }

    function getMouthRect(landmarks, videoWidth, containerWidth, containerHeight) {
      const mouthPoints = landmarks.getMouth().map(pt => ({
        x: mirrorX(pt.x, videoWidth, containerWidth),
        y: pt.y * containerHeight / video.videoHeight
      }));
      const xs = mouthPoints.map(p => p.x);
      const ys = mouthPoints.map(p => p.y);
      return {
        left: Math.min(...xs),
        right: Math.max(...xs),
        top: Math.min(...ys),
        bottom: Math.max(...ys)
      };
    }

    function isEmojiInMouth(mouthRect, emojiRect) {
      const eCenterX = emojiRect.left + emojiRect.width / 2;
      const eCenterY = emojiRect.top + emojiRect.height / 2;
      const containerRect = container.getBoundingClientRect();
      const relativeX = eCenterX - containerRect.left;
      const relativeY = eCenterY - containerRect.top;

      return (
        relativeX >= mouthRect.left &&
        relativeX <= mouthRect.right &&
        relativeY >= mouthRect.top &&
        relativeY <= mouthRect.bottom
      );
    }

    function placeEmojiRandomly() {
      const paddingX = container.clientWidth * 0.2;
      const paddingY = container.clientHeight * 0.2;

      const minX = paddingX;
      const maxX = container.clientWidth - emoji.clientWidth - paddingX;

      const minY = paddingY;
      const maxY = container.clientHeight - emoji.clientHeight - paddingY;

      const rawX = minX + Math.random() * (maxX - minX);
      const rawY = minY + Math.random() * (maxY - minY);

      const mirroredX = container.clientWidth - emoji.clientWidth - rawX;

      emoji.style.left = `${mirroredX}px`;
      emoji.style.top = `${rawY}px`;
    }

    async function detectLoop() {
      const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128, scoreThreshold: 0.5 });
      const result = await faceapi.detectSingleFace(video, options).withFaceLandmarks(true);

      if (result) {
        const landmarks = result.landmarks;
        if (isMouthOpen(landmarks)) {
          const mouthRect = getMouthRect(
            landmarks,
            video.videoWidth,
            container.clientWidth,
            container.clientHeight
          );

          // Draw red box for mouth
          mouthBox.style.left = `${mouthRect.left}px`;
          mouthBox.style.top = `${mouthRect.top}px`;
          mouthBox.style.width = `${mouthRect.right - mouthRect.left}px`;
          mouthBox.style.height = `${mouthRect.bottom - mouthRect.top}px`;
          mouthBox.style.display = 'block';

          const emojiRect = emoji.getBoundingClientRect();

          if (isEmojiInMouth(mouthRect, emojiRect)) {
            currentEmojiIndex = (currentEmojiIndex + 1) % EMOJIS.length;
            const newEmoji = EMOJIS[currentEmojiIndex];
            emoji.textContent = newEmoji;
            placeEmojiRandomly();

            // Speak the word
            const word = newEmoji === 'üçå' ? 'chicken' : 'banana';
            speak(word);
          }
        } else {
          mouthBox.style.display = 'none';
        }
      } else {
        mouthBox.style.display = 'none';
      }

      requestAnimationFrame(detectLoop);
    }

    async function init() {
      await loadModels();
      await video.play();
      placeEmojiRandomly();
      detectLoop();
    }

    video.onloadedmetadata = init;
    startCamera();
  </script>
</body>
</html>
